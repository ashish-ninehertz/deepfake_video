{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a238bc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hbd\n"
     ]
    }
   ],
   "source": [
    "print(\"hbd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe53f04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: rename /Users/nhz/kaggle.json to /Users/nhz/.kaggle/kaggle.json: No such file or directory\n",
      "chmod: /Users/nhz/.kaggle/kaggle.json: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!mv ~/kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eb1a7ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1830218467.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mmkdir -p ~/.kaggle\u001b[39m\n             ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "mkdir -p ~/.kaggle\n",
    "mv /Users/nhz/Desktop/deepfake/kaggle.json ~/.kaggle/\n",
    "chmod 600 ~/.kaggle/kaggle.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c06b6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: rename /Users/nhz/Users/nhz/Desktop/deepfake/kaggle.json to /Users/nhz/.kaggle/kaggle.json: No such file or directory\n",
      "chmod: /Users/nhz/.kaggle/kaggle.json: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!mv ~/Users/nhz/Desktop/deepfake/kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fda071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the distutils issue for Python 3.12\n",
    "import sys\n",
    "!{sys.executable} -m pip install setuptools --upgrade\n",
    "\n",
    "# Create a distutils compatibility layer if needed\n",
    "try:\n",
    "    import distutils.util\n",
    "    print(\"✅ distutils is available!\")\n",
    "except ImportError:\n",
    "    print(\"Installing distutils compatibility...\")\n",
    "    import sys\n",
    "    import types\n",
    "    \n",
    "    # Create a mock distutils module\n",
    "    distutils = types.ModuleType('distutils')\n",
    "    distutils.util = types.ModuleType('distutils.util')\n",
    "    \n",
    "    # Add to sys.modules\n",
    "    sys.modules['distutils'] = distutils\n",
    "    sys.modules['distutils.util'] = distutils.util\n",
    "    \n",
    "    print(\"✅ distutils compatibility layer created!\")\n",
    "\n",
    "# Also install any missing dependencies\n",
    "!{sys.executable} -m pip install --upgrade pip wheel\n",
    "!{sys.executable} -m pip install --upgrade tensorflow keras opencv-python numpy pillow matplotlib scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d55109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test TensorFlow imports after fixing distutils\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Force reload of tensorflow if it was previously imported with errors\n",
    "if 'tensorflow' in sys.modules:\n",
    "    del sys.modules['tensorflow']\n",
    "\n",
    "try:\n",
    "    print(\"Attempting to import TensorFlow...\")\n",
    "    import tensorflow as tf\n",
    "    print(\"✅ TensorFlow imported successfully!\")\n",
    "    print(f\"TensorFlow version: {tf.__version__}\")\n",
    "    \n",
    "    # Test specific imports that were failing\n",
    "    from tensorflow.keras.utils import img_to_array\n",
    "    from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "    print(\"✅ All TensorFlow Keras imports successful!\")\n",
    "    \n",
    "    # Test basic functionality\n",
    "    print(\"Testing TensorFlow functionality...\")\n",
    "    x = tf.constant([1, 2, 3, 4])\n",
    "    print(f\"✅ TensorFlow is working! Test tensor: {x}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    print(\"Trying alternative approach...\")\n",
    "    \n",
    "    # Alternative: Try installing specific TensorFlow version\n",
    "    !{sys.executable} -m pip install tensorflow==2.15.0 --upgrade\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        print(\"✅ TensorFlow 2.15.0 imported successfully!\")\n",
    "    except Exception as e2:\n",
    "        print(f\"❌ Still failed: {e2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1a8cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from pylab import *\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c2e58d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frame_folder = 'deepfake-detection-challenge/train_sample_videos'\n",
    "with open(os.path.join(train_frame_folder, 'metadata.json'), 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deb438c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'FAKE', 'split': 'train', 'original': 'vudstovrck.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'jdubbvfswz.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'atvmxvwyns.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qzimuostzz.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'kbvibjhfzo.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ccfoszqabv.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'fjlyaizcwc.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ffcwhpnpuw.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'slwkmefgde.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'fysyrqfguw.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qjlhemtkxk.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'dlpoieqvfb.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qzimuostzz.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'proiippuup.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gxembgiarp.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'iufotyxgzb.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'aytzyidmgs.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'dkuayagnmc.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'jomvcqqars.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'sunqwnmlkx.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ygdgwyqyut.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'bzythlfnhq.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'lyvlnqduqg.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'yxyhvdlrgk.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'swedbyuehz.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'xlbnmndmku.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'meawmsgiti.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ppdpgwyjgm.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'fewcljwqkr.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'cppdvdejkc.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'tqhbgzfwsf.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'meawmsgiti.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'vcxckqbaya.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'xobhsemxmv.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'xwcggrygwl.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'fysyrqfguw.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'xxsxktyvzt.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'bulkxhhknf.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'edyncaijwx.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'jkddywriuf.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'uonshkejav.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'xngpzquyhs.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'fjlyaizcwc.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'meawmsgiti.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'inkqxytzyu.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'znjupdqnwo.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'jepguaulgf.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'dzyuwjkjui.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'upgerjvcjb.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'wwqiuiwdbz.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'mfzqxktxud.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qedsgieuqn.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ppdpgwyjgm.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ifbdbogiqn.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'mfzqxktxud.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'hyhjfdxqxy.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'jdubbvfswz.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'efwfxwwlbw.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gktjowiuqe.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qzklcjjxdq.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gbqrgajyca.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'rrcsuwgpnd.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'xclqbefnvc.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'cprhtltsjp.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ujzwwfkeia.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'meawmsgiti.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'topyiohccg.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'mfnowqfdwl.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'rvoudrbyac.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'xxrzzncksa.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'jjyfvzxwwx.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'djxdyjopjd.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'xnhcreiyqg.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'imzqmbfugn.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'cpjxareypw.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'fysyrqfguw.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'iyefnuagav.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ybjrqnqnno.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qtnjyomzwo.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'keecvpbncd.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'fecysfujzk.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'kysxawkest.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'xzvrgckqkz.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gxembgiarp.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'sgjnvxvcpu.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'woshnzbxmc.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'znpdbbsfvj.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'rlvgtsjyer.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'vcxckqbaya.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'yfsnwkbafm.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'kydlpqfrvv.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'tdohqkzvbk.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'yfsnwkbafm.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'mfpgdgsaxg.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'hyuipchisa.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ybjrqnqnno.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gjypopglvi.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'xqnykluhws.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'dbtbbhakdv.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'rrcsuwgpnd.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ptokilxwcx.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gneufaypol.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'vmospzljws.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'mmhqllmlew.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'fntskqfxxf.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'xnfwdpptym.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ellavthztb.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ytufbmkdlq.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'dbtbbhakdv.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'sfujxhuyje.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'oesxbvktem.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'bxzakyopjf.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'lmlyvmfbbe.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'cizlkenljw.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ytufbmkdlq.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'iklzfeueid.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'meawmsgiti.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'atvmxvwyns.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'xagsvjctmp.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'djxdyjopjd.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'yagllixjvh.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'uuxqylnzls.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ywvlvpvroj.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'fdcttsvjwf.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ubplsigbvj.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'brwrlczjvi.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gxhcuxulhi.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'drcyabprvt.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'xwcggrygwl.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'crezycjqyk.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'cyxlcuyznd.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'kgbkktcjxf.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'mgowkzsbyx.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'fhghkqdkhe.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'mmhqllmlew.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ekcrtigpab.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ywvlvpvroj.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'xzvrgckqkz.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gktjowiuqe.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gipbyjfxfp.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'liniegczcx.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ifjktxxiln.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'kgbkktcjxf.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'nvpluswotp.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'fdcttsvjwf.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'sqwvfgwdxr.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'vgqotmftcr.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'lietldeotq.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'svcnlasmeh.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gxhcuxulhi.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'itzmdwutdu.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'xngpzquyhs.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ehtdtkmmli.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'atvmxvwyns.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'euqpvnyxrb.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'kysxawkest.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gjypopglvi.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'fygviyzcjm.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ztbinwxgyu.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'tfoxelmnjx.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qypgyrxcme.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'puppdcffcj.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'topyiohccg.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'zrkinjhsuq.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'bwipwzzxxu.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'atkdltyyen.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qzimuostzz.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ztbinwxgyu.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'kwyvikrgmx.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'bwipwzzxxu.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'jomvcqqars.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'fpvduejzcw.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'tfoixxmpoo.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'swedbyuehz.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'vrsinxahfh.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'wgmbcqfgkp.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'vrsinxahfh.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'iklzfeueid.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'fkyrrigzpt.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'lkdlzpkukw.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'chtapglbcj.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'iiomvouemm.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gdfyzwykty.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'fecysfujzk.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qeumxirsme.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'kgbkktcjxf.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'wtreibcmgm.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'kgbkktcjxf.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qtnjyomzwo.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'dlpoieqvfb.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qapnbtdypb.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qeumxirsme.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'atvmxvwyns.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gbqrgajyca.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'caifxvsozs.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'meawmsgiti.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'atvmxvwyns.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'kdodrvufdh.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'atvmxvwyns.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qtnjyomzwo.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ffcwhpnpuw.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'jjyfvzxwwx.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'yxyhvdlrgk.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ellavthztb.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'iuzdfwsefw.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'wapebjxejr.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'luvasmspox.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qtnjyomzwo.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ijokcwewbs.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qokxxuayqn.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ptokilxwcx.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ljaifbsfuw.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ywvlvpvroj.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'bffwsjxghk.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'jzmdganfys.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'duycddgtrl.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'jszyyhamrh.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'uonshkejav.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'cppdvdejkc.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'tdohqkzvbk.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ehccixxzoe.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gbqrgajyca.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gneufaypol.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'fgfyrfyqay.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gmihbscmwq.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'smggzgxymo.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'jljpdojupu.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'zhfyuhonra.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'mmhqllmlew.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qeumxirsme.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'hcswybumab.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'rfzzrftgco.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ztbinwxgyu.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ezaajaswoe.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'tamayudqqx.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gnyspcpbhd.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'eckvhdusax.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'fkqptfouqw.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'xnfwdpptym.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ngdswpaqnt.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'kkzsnmrkqk.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'iiomvouemm.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qeumxirsme.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'zrkinjhsuq.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'iyefnuagav.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'kydlpqfrvv.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'rlldzrnmdn.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'yagllixjvh.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'jomvcqqars.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'dzyuwjkjui.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'dzyuwjkjui.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'nlerwupaqr.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ohnonevlro.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gjypopglvi.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'dakiztgtnw.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gzyzdcbuuv.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'iieoqptzec.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'fgfyrfyqay.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'fgfyrfyqay.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'slwkmefgde.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'kuelhabsmz.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'tmdformfqp.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'imzqmbfugn.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'yoavqsqobz.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'pylnolwenx.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'xwcggrygwl.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'bgwmmujlmc.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'pqvypayzrp.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'lyvlnqduqg.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'yjlsxqoauz.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ehccixxzoe.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'iufotyxgzb.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'fysyrqfguw.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'kgbkktcjxf.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'grnycmbdfu.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'kysxawkest.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'xngpzquyhs.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'itmwoyxbas.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'iieoqptzec.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'rjlgchzmfv.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qzklcjjxdq.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qzklcjjxdq.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'olakcrnuro.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'abarnvbtwb.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'lyvlnqduqg.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'xngpzquyhs.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'hqtepxaeqx.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gipbyjfxfp.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'bejhvclboh.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'nzquxipbye.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'avmjormvsx.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'sasoxcqisz.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ixuouyigxa.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'joeifeskbs.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'xzvrgckqkz.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ywvlvpvroj.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'jwcsqxzdlv.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'egghxjjmfg.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'tivkmbqgwp.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gipbyjfxfp.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qhkqqfznrg.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'dzyuwjkjui.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'cprhtltsjp.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ybjrqnqnno.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'lulmevqtla.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gbqrgajyca.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'kuelhabsmz.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'svcnlasmeh.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'dbnygxtwek.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'cmbzllswnl.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'nvpluswotp.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'grnycmbdfu.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gdfyzwykty.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'rrcsuwgpnd.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'ybetenmsye.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gomwfvijiv.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qeumxirsme.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'qzklcjjxdq.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gipbyjfxfp.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'wtreibcmgm.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'afoovlsmtx.mp4'}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'bdnaqemxmr.mp4'}\n",
      "{'label': 'REAL', 'split': 'train', 'original': None}\n",
      "{'label': 'FAKE', 'split': 'train', 'original': 'gjypopglvi.mp4'}\n"
     ]
    }
   ],
   "source": [
    "for key, value in data.items():\n",
    "    print(data[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b92fcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Videoos::  77\n",
      "Fake Videos::  323\n"
     ]
    }
   ],
   "source": [
    "fake_count=0\n",
    "real_count=0\n",
    "\n",
    "for key, value in data.items():\n",
    "    if \"FAKE\" == data[key]['label']:\n",
    "        fake_count+=1\n",
    "    if \"REAL\" == data[key]['label']:\n",
    "        real_count+=1\n",
    "print(\"Real Videoos:: \", real_count)\n",
    "print(\"Fake Videos:: \", fake_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78371664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing video 1: cdaxixbosp.mp4, saved 10 frames\n",
      "Done processing video 2: btiysiskpf.mp4, saved 10 frames\n",
      "Done processing video 3: clihsshdkq.mp4, saved 10 frames\n",
      "Done processing video 4: alvgwypubw.mp4, saved 10 frames\n",
      "Done processing video 5: eqvuznuwsa.mp4, saved 10 frames\n",
      "Done processing video 6: eudeqjhdfd.mp4, saved 10 frames\n",
      "Done processing video 7: eeyhxisdfh.mp4, saved 10 frames\n",
      "Done processing video 8: cizlkenljw.mp4, saved 10 frames\n",
      "Done processing video 9: bndybcqhfr.mp4, saved 10 frames\n",
      "Done processing video 10: cuzrgrbvil.mp4, saved 10 frames\n",
      "Done processing video 11: atyntldecu.mp4, saved 10 frames\n",
      "Done processing video 12: bggsurpgpr.mp4, saved 10 frames\n",
      "Done processing video 13: eckvhdusax.mp4, saved 10 frames\n",
      "Done processing video 14: dvakowbgbt.mp4, saved 10 frames\n",
      "Done processing video 15: dqqtjcryjv.mp4, saved 10 frames\n",
      "Done processing video 16: djvutyvaio.mp4, saved 0 frames\n",
      "Done processing video 17: dzwkmcwkwl.mp4, saved 10 frames\n",
      "Done processing video 18: bpapbctoao.mp4, saved 10 frames\n",
      "Done processing video 19: aettqgevhz.mp4, saved 10 frames\n",
      "Done processing video 20: bbhtdfuqxq.mp4, saved 10 frames\n",
      "Done processing video 21: caifxvsozs.mp4, saved 10 frames\n",
      "Done processing video 22: bgaogsjehq.mp4, saved 10 frames\n",
      "Done processing video 23: agqphdxmwt.mp4, saved 10 frames\n",
      "Done processing video 24: ebywfrmhtd.mp4, saved 10 frames\n",
      "Done processing video 25: bsqgziaylx.mp4, saved 10 frames\n",
      "Done processing video 26: ciyoudyhly.mp4, saved 10 frames\n",
      "Done processing video 27: bxzakyopjf.mp4, saved 10 frames\n",
      "Done processing video 28: cknyxaqouy.mp4, saved 10 frames\n",
      "Done processing video 29: avnqydkqjj.mp4, saved 10 frames\n",
      "Done processing video 30: dakiztgtnw.mp4, saved 10 frames\n",
      "Done processing video 31: acifjvzvpm.mp4, saved 10 frames\n",
      "Done processing video 32: dofusvhnib.mp4, saved 10 frames\n",
      "Done processing video 33: ahqqqilsxt.mp4, saved 10 frames\n",
      "Done processing video 34: avtycwsgyb.mp4, saved 10 frames\n",
      "Done processing video 35: cvaksbpssm.mp4, saved 10 frames\n",
      "Done processing video 36: brwrlczjvi.mp4, saved 10 frames\n",
      "Done processing video 37: bgwmmujlmc.mp4, saved 10 frames\n",
      "Done processing video 38: dhkwmjxwrn.mp4, saved 10 frames\n",
      "Done processing video 39: bmjmjmbglm.mp4, saved 10 frames\n",
      "Done processing video 40: emgjphonqb.mp4, saved 10 frames\n",
      "Done processing video 41: bzmdrafeex.mp4, saved 10 frames\n",
      "Done processing video 42: dsgpbgsrdm.mp4, saved 10 frames\n",
      "Done processing video 43: afoovlsmtx.mp4, saved 10 frames\n",
      "Done processing video 44: ebeknhudxq.mp4, saved 0 frames\n",
      "Done processing video 45: ccfoszqabv.mp4, saved 10 frames\n",
      "Done processing video 46: dnexlwbcxq.mp4, saved 10 frames\n",
      "Done processing video 47: ensyyivobf.mp4, saved 10 frames\n",
      "Done processing video 48: apgjqzkoma.mp4, saved 10 frames\n",
      "Done processing video 49: bqeiblbxtl.mp4, saved 10 frames\n",
      "Done processing video 50: eqjscdagiv.mp4, saved 10 frames\n",
      "Done processing video 51: ejkqesyvam.mp4, saved 10 frames\n",
      "Done processing video 52: bilnggbxgu.mp4, saved 10 frames\n",
      "Done processing video 53: bulkxhhknf.mp4, saved 10 frames\n",
      "Done processing video 54: cdphtzqrvp.mp4, saved 10 frames\n",
      "Done processing video 55: cmxcfkrjiv.mp4, saved 10 frames\n",
      "Done processing video 56: cwsbspfzck.mp4, saved 10 frames\n",
      "Done processing video 57: bsfmwclnqy.mp4, saved 10 frames\n",
      "Done processing video 58: ajqslcypsw.mp4, saved 10 frames\n",
      "Done processing video 59: eebrkicpry.mp4, saved 10 frames\n",
      "Done processing video 60: aklqzsddfl.mp4, saved 10 frames\n",
      "Done processing video 61: aqpnvjhuzw.mp4, saved 10 frames\n",
      "Done processing video 62: bvzjkezkms.mp4, saved 10 frames\n",
      "Done processing video 63: bmhvktyiwp.mp4, saved 10 frames\n",
      "Done processing video 64: acxnxvbsxk.mp4, saved 10 frames\n",
      "Done processing video 65: cyboodqqyr.mp4, saved 10 frames\n",
      "Done processing video 66: czkdanyadc.mp4, saved 10 frames\n",
      "Done processing video 67: esgftaficx.mp4, saved 10 frames\n",
      "Done processing video 68: aagfhgtpmv.mp4, saved 10 frames\n",
      "Done processing video 69: bmbbkwmxqj.mp4, saved 10 frames\n",
      "Done processing video 70: dqnyszdong.mp4, saved 0 frames\n",
      "Done processing video 71: btunxncpjh.mp4, saved 10 frames\n",
      "Done processing video 72: bnbuonyoje.mp4, saved 10 frames\n",
      "Done processing video 73: bhpwpydzpo.mp4, saved 10 frames\n",
      "Done processing video 74: bbvgxeczei.mp4, saved 0 frames\n",
      "Done processing video 75: apogckdfrz.mp4, saved 10 frames\n",
      "Done processing video 76: esnntzzajv.mp4, saved 10 frames\n",
      "Done processing video 77: chzieimrwu.mp4, saved 10 frames\n",
      "Done processing video 78: dhcndnuwta.mp4, saved 10 frames\n",
      "Done processing video 79: awukslzjra.mp4, saved 10 frames\n",
      "Done processing video 80: amowujxmzc.mp4, saved 10 frames\n",
      "Done processing video 81: dbhoxkblzx.mp4, saved 10 frames\n",
      "Done processing video 82: akvmwkdyuv.mp4, saved 10 frames\n",
      "Done processing video 83: bqnymlsayl.mp4, saved 10 frames\n",
      "Done processing video 84: aevrfsexku.mp4, saved 10 frames\n",
      "Done processing video 85: abqwwspghj.mp4, saved 10 frames\n",
      "Done processing video 86: byofowlkki.mp4, saved 10 frames\n",
      "Done processing video 87: cycacemkmt.mp4, saved 0 frames\n",
      "Done processing video 88: arkroixhey.mp4, saved 10 frames\n",
      "Done processing video 89: asmpfjfzif.mp4, saved 10 frames\n",
      "Done processing video 90: eprybmbpba.mp4, saved 10 frames\n",
      "Done processing video 91: btugrnoton.mp4, saved 10 frames\n",
      "Done processing video 92: bwipwzzxxu.mp4, saved 10 frames\n",
      "Done processing video 93: cwwandrkus.mp4, saved 10 frames\n",
      "Done processing video 94: emaalmsonj.mp4, saved 10 frames\n",
      "Done processing video 95: bqkdbcqjvb.mp4, saved 0 frames\n",
      "Done processing video 96: aytzyidmgs.mp4, saved 10 frames\n",
      "Done processing video 97: avssvvsdhz.mp4, saved 10 frames\n",
      "Done processing video 98: avibnnhwhp.mp4, saved 10 frames\n",
      "Done processing video 99: bchnbulevv.mp4, saved 10 frames\n",
      "Done processing video 100: btohlidmru.mp4, saved 10 frames\n",
      "Done processing video 101: elginszwtk.mp4, saved 10 frames\n",
      "Done processing video 102: augtsuxpzc.mp4, saved 10 frames\n",
      "Done processing video 103: ecujsjhscd.mp4, saved 10 frames\n",
      "Done processing video 104: agrmhtjdlk.mp4, saved 10 frames\n",
      "Done processing video 105: edyncaijwx.mp4, saved 10 frames\n",
      "Done processing video 106: cpjxareypw.mp4, saved 10 frames\n",
      "Done processing video 107: cobjrlugvp.mp4, saved 10 frames\n",
      "Done processing video 108: ehtdtkmmli.mp4, saved 10 frames\n",
      "Done processing video 109: anpuvshzoo.mp4, saved 10 frames\n",
      "Done processing video 110: eqnoqyfquo.mp4, saved 10 frames\n",
      "Done processing video 111: bdnaqemxmr.mp4, saved 10 frames\n",
      "Done processing video 112: chtapglbcj.mp4, saved 10 frames\n",
      "Done processing video 113: atkdltyyen.mp4, saved 10 frames\n",
      "Done processing video 114: cmbzllswnl.mp4, saved 10 frames\n",
      "Done processing video 115: asaxgevnnp.mp4, saved 10 frames\n",
      "Done processing video 116: egghxjjmfg.mp4, saved 10 frames\n",
      "Done processing video 117: chviwxsfhg.mp4, saved 10 frames\n",
      "Done processing video 118: bmjzrlszhi.mp4, saved 10 frames\n",
      "Done processing video 119: dbtbbhakdv.mp4, saved 10 frames\n",
      "Done processing video 120: dsjbknkujw.mp4, saved 10 frames\n",
      "Done processing video 121: ckkuyewywx.mp4, saved 10 frames\n",
      "Done processing video 122: abarnvbtwb.mp4, saved 10 frames\n",
      "Done processing video 123: dkuayagnmc.mp4, saved 10 frames\n",
      "Done processing video 124: duycddgtrl.mp4, saved 10 frames\n",
      "Done processing video 125: ekcrtigpab.mp4, saved 10 frames\n",
      "Done processing video 126: dxbqjxrhin.mp4, saved 10 frames\n",
      "Done processing video 127: beboztfcme.mp4, saved 10 frames\n",
      "Done processing video 128: clrycekyst.mp4, saved 10 frames\n",
      "Done processing video 129: bffwsjxghk.mp4, saved 10 frames\n",
      "Done processing video 130: cppdvdejkc.mp4, saved 10 frames\n",
      "Done processing video 131: dlpoieqvfb.mp4, saved 10 frames\n",
      "Done processing video 132: axntxmycwd.mp4, saved 10 frames\n",
      "Done processing video 133: ckjaibzfxa.mp4, saved 10 frames\n",
      "Done processing video 134: cfxkpiweqt.mp4, saved 10 frames\n",
      "Done processing video 135: aelfnikyqj.mp4, saved 10 frames\n",
      "Done processing video 136: bejhvclboh.mp4, saved 10 frames\n",
      "Done processing video 137: bddjdhzfze.mp4, saved 10 frames\n",
      "Done processing video 138: aybumesmpk.mp4, saved 10 frames\n",
      "Done processing video 139: crezycjqyk.mp4, saved 10 frames\n",
      "Done processing video 140: cprhtltsjp.mp4, saved 10 frames\n",
      "Done processing video 141: bzythlfnhq.mp4, saved 10 frames\n",
      "Done processing video 142: aybgughjxh.mp4, saved 10 frames\n",
      "Done processing video 143: efwfxwwlbw.mp4, saved 10 frames\n",
      "Done processing video 144: bwhlgysghg.mp4, saved 10 frames\n",
      "Done processing video 145: eggbjzxnmg.mp4, saved 10 frames\n",
      "Done processing video 146: dhxctgyoqj.mp4, saved 10 frames\n",
      "Done processing video 147: dkzvdrzcnr.mp4, saved 10 frames\n",
      "Done processing video 148: djxdyjopjd.mp4, saved 10 frames\n",
      "Done processing video 149: drcyabprvt.mp4, saved 10 frames\n",
      "Done processing video 150: ehccixxzoe.mp4, saved 10 frames\n",
      "Done processing video 151: atvmxvwyns.mp4, saved 0 frames\n",
      "Done processing video 152: cyxlcuyznd.mp4, saved 10 frames\n",
      "Done processing video 153: bgvhtpzknn.mp4, saved 10 frames\n",
      "Done processing video 154: dbnygxtwek.mp4, saved 10 frames\n",
      "Done processing video 155: erlvuvjsjf.mp4, saved 10 frames\n",
      "Done processing video 156: beyebyhrph.mp4, saved 10 frames\n",
      "Done processing video 157: dzyuwjkjui.mp4, saved 10 frames\n",
      "Done processing video 158: ellavthztb.mp4, saved 10 frames\n",
      "Done processing video 159: avmjormvsx.mp4, saved 10 frames\n",
      "Done processing video 160: ddepeddixj.mp4, saved 10 frames\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import dlib\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = (299, 299)  # Resize detected faces to this size\n",
    "MOTION_THRESHOLD = 20  # Lowered threshold for detecting motion between frames\n",
    "FRAME_SKIP = 2        # Reduced frame skip to ensure more frames are processed\n",
    "\n",
    "# Initialize Dlib's frontal face detector (can switch to Haar cascades, MTCNN, or other)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "def extract_faces_from_frame(frame, detector):\n",
    "    \"\"\"\n",
    "    Detects faces in a frame and returns the resized faces.\n",
    "\n",
    "    Parameters:\n",
    "    - frame: The video frame to process.\n",
    "    - detector: Dlib face detector.\n",
    "\n",
    "    Returns:\n",
    "    - resized_faces (list): List of resized faces detected in the frame.\n",
    "    \"\"\"\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray_frame)\n",
    "    resized_faces = []\n",
    "\n",
    "    for face in faces:\n",
    "        x1, y1, x2, y2 = face.left(), face.top(), face.right(), face.bottom()\n",
    "        crop_img = frame[y1:y2, x1:x2]\n",
    "        if crop_img.size != 0:  # Ensure cropped image is valid\n",
    "            resized_face = cv2.resize(crop_img, IMG_SIZE)\n",
    "            resized_faces.append(resized_face)\n",
    "\n",
    "    # Debug: Log the number of faces detected\n",
    "    #print(f\"Detected {len(resized_faces)} faces in current frame\")\n",
    "    return resized_faces\n",
    "\n",
    "def process_frame(video_path, detector, frame_skip):\n",
    "    \"\"\"\n",
    "    Processes frames to extract motion and face data concurrently.\n",
    "\n",
    "    Parameters:\n",
    "    - cap: OpenCV VideoCapture object.\n",
    "    - detector: Dlib face detector.\n",
    "    - frame_skip (int): Number of frames to skip for processing.\n",
    "\n",
    "    Returns:\n",
    "    - motion_frames (list): List of motion-based face images.\n",
    "    - all_faces (list): List of all detected faces for fallback.\n",
    "    \"\"\"\n",
    "    prev_frame = None\n",
    "    frame_count = 0\n",
    "    motion_frames = []\n",
    "    all_faces = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Skip frames to improve processing speed\n",
    "        if frame_count % frame_skip != 0:\n",
    "            frame_count += 1\n",
    "            continue\n",
    "\n",
    "        # Debug: Log frame number being processed\n",
    "        #print(f\"Processing frame {frame_count}\")\n",
    "\n",
    "        # # Resize frame to reduce processing time (optional, adjust size as needed)\n",
    "        # frame = cv2.resize(frame, (640, 360))\n",
    "\n",
    "        # Extract faces from the current frame\n",
    "        faces = extract_faces_from_frame(frame, detector)\n",
    "        all_faces.extend(faces)  # Store all faces detected, including non-motion\n",
    "\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if prev_frame is None:\n",
    "            prev_frame = gray_frame\n",
    "            frame_count += 1\n",
    "            continue\n",
    "\n",
    "        # Calculate frame difference to detect motion\n",
    "        frame_diff = cv2.absdiff(prev_frame, gray_frame)\n",
    "        motion_score = np.sum(frame_diff)\n",
    "\n",
    "        # Debug: Log the motion score\n",
    "        #print(f\"Motion score: {motion_score}\")\n",
    "\n",
    "        # Check if motion is above the defined threshold and add the face to motion frames\n",
    "        if motion_score > MOTION_THRESHOLD and faces:\n",
    "            motion_frames.extend(faces)\n",
    "\n",
    "        prev_frame = gray_frame\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    return motion_frames, all_faces\n",
    "\n",
    "def select_well_distributed_frames(motion_frames, all_faces, no_of_frames):\n",
    "    \"\"\"\n",
    "    Selects well-distributed frames from the detected motion and fallback faces.\n",
    "\n",
    "    Parameters:\n",
    "    - motion_frames (list): List of frames with detected motion.\n",
    "    - all_faces (list): List of all detected faces.\n",
    "    - no_of_frames (int): Required number of frames.\n",
    "\n",
    "    Returns:\n",
    "    - final_frames (list): List of selected frames.\n",
    "    \"\"\"\n",
    "    # Case 1: Motion frames exceed the required number\n",
    "    if len(motion_frames) >= no_of_frames:\n",
    "        interval = len(motion_frames) // no_of_frames\n",
    "        distributed_motion_frames = [motion_frames[i * interval] for i in range(no_of_frames)]\n",
    "        return distributed_motion_frames\n",
    "\n",
    "    # Case 2: Motion frames are less than the required number\n",
    "    needed_frames = no_of_frames - len(motion_frames)\n",
    "\n",
    "    # If all frames together are still less than needed, return all frames available\n",
    "    if len(motion_frames) + len(all_faces) < no_of_frames:\n",
    "        #print(f\"Returning all available frames: {len(motion_frames) + len(all_faces)}\")\n",
    "        return motion_frames + all_faces\n",
    "\n",
    "    interval = max(1, len(all_faces) // needed_frames)\n",
    "    additional_faces = [all_faces[i * interval] for i in range(needed_frames)]\n",
    "\n",
    "    combined_frames = motion_frames + additional_faces\n",
    "    interval = max(1, len(combined_frames) // no_of_frames)\n",
    "    final_frames = [combined_frames[i * interval] for i in range(no_of_frames)]\n",
    "\n",
    "    return final_frames\n",
    "\n",
    "def create_dataset(no_of_frames, train_frame_folder):\n",
    "    \"\"\"\n",
    "    Create dataset from DFDC videos by extracting frames based on motion and saving detected faces.\n",
    "\n",
    "    Parameters:\n",
    "    - no_of_frames (int): Number of frames to save per video.\n",
    "    - train_frame_folder (str): Directory containing video files and metadata.json.\n",
    "    \"\"\"\n",
    "    fake_count = 0\n",
    "    videoprocessedcount = 0\n",
    "\n",
    "    # Load metadata for video labels\n",
    "    with open(os.path.join(train_frame_folder, 'metadata.json'), 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    list_of_train_data = [f for f in os.listdir(train_frame_folder) if f.endswith('.mp4')]\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        for vid in list_of_train_data:\n",
    "            if data[vid]['label'] == \"FAKE\" and fake_count >= 77:\n",
    "                continue\n",
    "            \n",
    "            video_path = os.path.join(train_frame_folder, vid)\n",
    "\n",
    "            save_dir = 'Dataset/real' if data[vid]['label'] == 'REAL' else 'Dataset/fake'\n",
    "\n",
    "            # Extract motion frames and all faces concurrently\n",
    "            motion_frames, all_faces = process_frame(video_path, detector, FRAME_SKIP)\n",
    "\n",
    "            # Select well-distributed frames based on the motion and fallback frames\n",
    "            final_frames = select_well_distributed_frames(motion_frames, all_faces, no_of_frames)\n",
    "\n",
    "            if data[vid]['label'] == \"FAKE\" and len(final_frames)!=0:\n",
    "                fake_count += 1\n",
    "\n",
    "            # Save the extracted faces\n",
    "            for idx, face in enumerate(final_frames):\n",
    "                filename = os.path.join(save_dir, f'{vid.split(\".\")[0]}_{idx}.png')\n",
    "                executor.submit(cv2.imwrite, filename, face)  # Save images concurrently\n",
    "\n",
    "            videoprocessedcount += 1\n",
    "            print(f\"Done processing video {videoprocessedcount}: {vid}, saved {len(final_frames)} frames\")\n",
    "\n",
    "# Example usage\n",
    "no_of_frames = 10  # Number of frames to extract per video\n",
    "train_frame_folder = 'deepfake-detection-challenge/train_sample_videos'  # Replace with the actual path to the training folder\n",
    "create_dataset(no_of_frames, train_frame_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "397b17ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of images in the 'fake' directory: 770\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if the directory exists\n",
    "fake_images_directory = 'Dataset/fake'\n",
    "\n",
    "if os.path.exists(fake_images_directory):\n",
    "    # Count the number of image files in the directory\n",
    "    fake_images_count = len([file for file in os.listdir(fake_images_directory) if file.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff'))])\n",
    "    print(f\"The number of images in the 'fake' directory: {fake_images_count}\")\n",
    "else:\n",
    "    print(\"The directory does not exist. Please check the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dad1864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in ./deepfakevenv/lib/python3.12/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in ./deepfakevenv/lib/python3.12/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: numpy in ./deepfakevenv/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in ./deepfakevenv/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./deepfakevenv/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./deepfakevenv/lib/python3.12/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./deepfakevenv/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./deepfakevenv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: tensorflow in ./deepfakevenv/lib/python3.12/site-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (4.25.8)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./deepfakevenv/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.9)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./deepfakevenv/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./deepfakevenv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in ./deepfakevenv/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in ./deepfakevenv/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in ./deepfakevenv/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./deepfakevenv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./deepfakevenv/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./deepfakevenv/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./deepfakevenv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install numpy\n",
    "!pip install scikit-learn\n",
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70f59dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m==>\u001b[0m \u001b[1mFetching downloads for: \u001b[32mpython-setuptools\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/python-setuptools/manifests/80.\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mpython-setuptools\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/python-setuptools/blobs/sha256:\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring python-setuptools--80.9.0.all.bottle.tar.gz\u001b[0m\n",
      "🍺  /opt/homebrew/Cellar/python-setuptools/80.9.0: 1,000 files, 8MB\n",
      "\u001b[34m==>\u001b[0m \u001b[1mRunning `brew cleanup python-setuptools`...\u001b[0m\n",
      "Disable this behaviour by setting `HOMEBREW_NO_INSTALL_CLEANUP=1`.\n",
      "Hide these hints with `HOMEBREW_NO_ENV_HINTS=1` (see `man brew`).\n",
      "\u001b[34m==>\u001b[0m \u001b[1mNo outdated dependents to upgrade!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!brew install python-setuptools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417fdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./deepfakevenv/lib/python3.12/site-packages (25.2)\n",
      "Requirement already satisfied: tensorflow in ./deepfakevenv/lib/python3.12/site-packages (2.17.0)\n",
      "Requirement already satisfied: opencv-python in ./deepfakevenv/lib/python3.12/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: scikit-learn in ./deepfakevenv/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy in ./deepfakevenv/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (4.25.8)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./deepfakevenv/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.9)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./deepfakevenv/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./deepfakevenv/lib/python3.12/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./deepfakevenv/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./deepfakevenv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./deepfakevenv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in ./deepfakevenv/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in ./deepfakevenv/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in ./deepfakevenv/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./deepfakevenv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./deepfakevenv/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./deepfakevenv/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./deepfakevenv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install tensorflow opencv-python scikit-learn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8e3e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-nightly in ./deepfakevenv/lib/python3.12/site-packages (2.21.0.dev20250908)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./deepfakevenv/lib/python3.12/site-packages (from tf-nightly) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./deepfakevenv/lib/python3.12/site-packages (from tf-nightly) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=25.2.10 in ./deepfakevenv/lib/python3.12/site-packages (from tf-nightly) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./deepfakevenv/lib/python3.12/site-packages (from tf-nightly) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in ./deepfakevenv/lib/python3.12/site-packages (from tf-nightly) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./deepfakevenv/lib/python3.12/site-packages (from tf-nightly) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in ./deepfakevenv/lib/python3.12/site-packages (from tf-nightly) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./deepfakevenv/lib/python3.12/site-packages (from tf-nightly) (24.2)\n",
      "Requirement already satisfied: protobuf<8.0.0,>=6.31.1 in ./deepfakevenv/lib/python3.12/site-packages (from tf-nightly) (6.32.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./deepfakevenv/lib/python3.12/site-packages (from tf-nightly) (2.32.5)\n",
      "Requirement already satisfied: setuptools in ./deepfakevenv/lib/python3.12/site-packages (from tf-nightly) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./deepfakevenv/lib/python3.12/site-packages (from tf-nightly) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./deepfakevenv/lib/python3.12/site-packages (from tf-nightly) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in ./deepfakevenv/lib/python3.12/site-packages (from tf-nightly) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./deepfakevenv/lib/python3.12/site-packages (from tf-nightly) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./deepfakevenv/lib/python3.12/site-packages (from tf-nightly) (1.74.0)\n",
      "Requirement already satisfied: tb-nightly~=2.20.0.a in ./deepfakevenv/lib/python3.12/site-packages (from tf-nightly) (2.20.0a20250717)\n",
      "Requirement already satisfied: keras-nightly>=3.10.0.dev in ./deepfakevenv/lib/python3.12/site-packages (from tf-nightly) (3.12.0.dev2025090903)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./deepfakevenv/lib/python3.12/site-packages (from tf-nightly) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./deepfakevenv/lib/python3.12/site-packages (from tf-nightly) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in ./deepfakevenv/lib/python3.12/site-packages (from tf-nightly) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tf-nightly) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tf-nightly) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tf-nightly) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tf-nightly) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./deepfakevenv/lib/python3.12/site-packages (from tb-nightly~=2.20.0.a->tf-nightly) (3.9)\n",
      "Requirement already satisfied: pillow in ./deepfakevenv/lib/python3.12/site-packages (from tb-nightly~=2.20.0.a->tf-nightly) (10.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./deepfakevenv/lib/python3.12/site-packages (from tb-nightly~=2.20.0.a->tf-nightly) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./deepfakevenv/lib/python3.12/site-packages (from tb-nightly~=2.20.0.a->tf-nightly) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./deepfakevenv/lib/python3.12/site-packages (from astunparse>=1.6.0->tf-nightly) (0.45.1)\n",
      "Requirement already satisfied: rich in ./deepfakevenv/lib/python3.12/site-packages (from keras-nightly>=3.10.0.dev->tf-nightly) (13.9.4)\n",
      "Requirement already satisfied: namex in ./deepfakevenv/lib/python3.12/site-packages (from keras-nightly>=3.10.0.dev->tf-nightly) (0.1.0)\n",
      "Requirement already satisfied: optree in ./deepfakevenv/lib/python3.12/site-packages (from keras-nightly>=3.10.0.dev->tf-nightly) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./deepfakevenv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tb-nightly~=2.20.0.a->tf-nightly) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./deepfakevenv/lib/python3.12/site-packages (from rich->keras-nightly>=3.10.0.dev->tf-nightly) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./deepfakevenv/lib/python3.12/site-packages (from rich->keras-nightly>=3.10.0.dev->tf-nightly) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./deepfakevenv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras-nightly>=3.10.0.dev->tf-nightly) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01a0049a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (6.32.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (1.74.0)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./deepfakevenv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
      "Requirement already satisfied: pillow in ./deepfakevenv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (10.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./deepfakevenv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./deepfakevenv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in ./deepfakevenv/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in ./deepfakevenv/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in ./deepfakevenv/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./deepfakevenv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./deepfakevenv/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./deepfakevenv/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./deepfakevenv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.20.0-cp312-cp312-macosx_12_0_arm64.whl (200.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorboard, keras, tensorflow\n",
      "\u001b[2K  Attempting uninstall: tensorboard\n",
      "\u001b[2K    Found existing installation: tensorboard 2.17.1\n",
      "\u001b[2K    Uninstalling tensorboard-2.17.1:\n",
      "\u001b[2K      Successfully uninstalled tensorboard-2.17.1\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [tensorflow]3\u001b[0m [tensorflow]\n",
      "\u001b[1A\u001b[2KSuccessfully installed keras-3.11.3 tensorboard-2.20.0 tensorflow-2.20.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "239c6e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.17.0 in ./deepfakevenv/lib/python3.12/site-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (4.25.8)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (2.32.5)\n",
      "Requirement already satisfied: setuptools in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (1.74.0)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (3.11.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (1.26.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./deepfakevenv/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.9)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./deepfakevenv/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./deepfakevenv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow==2.17.0) (0.45.1)\n",
      "Requirement already satisfied: rich in ./deepfakevenv/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow==2.17.0) (13.9.4)\n",
      "Requirement already satisfied: namex in ./deepfakevenv/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow==2.17.0) (0.1.0)\n",
      "Requirement already satisfied: optree in ./deepfakevenv/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow==2.17.0) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./deepfakevenv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow==2.17.0) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./deepfakevenv/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow==2.17.0) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./deepfakevenv/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow==2.17.0) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./deepfakevenv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow==2.17.0) (0.1.2)\n",
      "Requirement already satisfied: keras-nightly==3.5.0.dev2024091203 in ./deepfakevenv/lib/python3.12/site-packages (3.5.0.dev2024091203)\n",
      "Requirement already satisfied: absl-py in ./deepfakevenv/lib/python3.12/site-packages (from keras-nightly==3.5.0.dev2024091203) (2.3.1)\n",
      "Requirement already satisfied: numpy in ./deepfakevenv/lib/python3.12/site-packages (from keras-nightly==3.5.0.dev2024091203) (1.26.4)\n",
      "Requirement already satisfied: rich in ./deepfakevenv/lib/python3.12/site-packages (from keras-nightly==3.5.0.dev2024091203) (13.9.4)\n",
      "Requirement already satisfied: namex in ./deepfakevenv/lib/python3.12/site-packages (from keras-nightly==3.5.0.dev2024091203) (0.1.0)\n",
      "Requirement already satisfied: h5py in ./deepfakevenv/lib/python3.12/site-packages (from keras-nightly==3.5.0.dev2024091203) (3.14.0)\n",
      "Requirement already satisfied: optree in ./deepfakevenv/lib/python3.12/site-packages (from keras-nightly==3.5.0.dev2024091203) (0.17.0)\n",
      "Requirement already satisfied: ml-dtypes in ./deepfakevenv/lib/python3.12/site-packages (from keras-nightly==3.5.0.dev2024091203) (0.4.1)\n",
      "Requirement already satisfied: packaging in ./deepfakevenv/lib/python3.12/site-packages (from keras-nightly==3.5.0.dev2024091203) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in ./deepfakevenv/lib/python3.12/site-packages (from optree->keras-nightly==3.5.0.dev2024091203) (4.15.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./deepfakevenv/lib/python3.12/site-packages (from rich->keras-nightly==3.5.0.dev2024091203) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./deepfakevenv/lib/python3.12/site-packages (from rich->keras-nightly==3.5.0.dev2024091203) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./deepfakevenv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras-nightly==3.5.0.dev2024091203) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.17.0\n",
    "!pip install keras-nightly==3.5.0.dev2024091203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b7b26d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 2.17.0\n",
      "Uninstalling tensorflow-2.17.0:\n",
      "  Successfully uninstalled tensorflow-2.17.0\n",
      "Found existing installation: keras 3.11.3\n",
      "Uninstalling keras-3.11.3:\n",
      "  Successfully uninstalled keras-3.11.3\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall tensorflow keras -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9de3569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.17.0\n",
      "  Using cached tensorflow-2.17.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (4.25.8)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (2.32.5)\n",
      "Requirement already satisfied: setuptools in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (1.74.0)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (2.17.1)\n",
      "Collecting keras>=3.2.0 (from tensorflow==2.17.0)\n",
      "  Using cached keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorflow==2.17.0) (1.26.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./deepfakevenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./deepfakevenv/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.9)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./deepfakevenv/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./deepfakevenv/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./deepfakevenv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow==2.17.0) (0.45.1)\n",
      "Requirement already satisfied: rich in ./deepfakevenv/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow==2.17.0) (13.9.4)\n",
      "Requirement already satisfied: namex in ./deepfakevenv/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow==2.17.0) (0.1.0)\n",
      "Requirement already satisfied: optree in ./deepfakevenv/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow==2.17.0) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./deepfakevenv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow==2.17.0) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./deepfakevenv/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow==2.17.0) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./deepfakevenv/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow==2.17.0) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./deepfakevenv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow==2.17.0) (0.1.2)\n",
      "Using cached tensorflow-2.17.0-cp312-cp312-macosx_12_0_arm64.whl (236.3 MB)\n",
      "Using cached keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "Installing collected packages: keras, tensorflow\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [tensorflow]2\u001b[0m [tensorflow]\n",
      "\u001b[1A\u001b[2KSuccessfully installed keras-3.11.3 tensorflow-2.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.17.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d982d355",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m img_to_array\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapplications\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minception_v3\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m preprocess_input\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Constants\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow.keras'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "# Constants\n",
    "IMG_SIZE = (299, 299)  # Target image size for InceptionV3\n",
    "MAX_FRAMES = 10        # Maximum number of frames per sequence\n",
    "REAL_DIR = 'real'      # Directory containing images of real samples\n",
    "FAKE_DIR = 'fake'      # Directory containing images of fake samples\n",
    "\n",
    "def load_images_from_directory(directory, label):\n",
    "    \"\"\"\n",
    "    Load images from the specified directory, group them by videoname, preprocess, and pad sequences.\n",
    "    \n",
    "    Parameters:\n",
    "    - directory (str): Path to the directory containing images.\n",
    "    - label (int): Label for the samples (0 for real, 1 for fake).\n",
    "    \n",
    "    Returns:\n",
    "    - data (np.array): Array of processed sequences of images.\n",
    "    - labels (np.array): Array of corresponding labels.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    video_frames = defaultdict(list)  # Dictionary to hold frames grouped by videoname\n",
    "\n",
    "    # Iterate over all images in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.png'):\n",
    "            # Extract the videoname (before the first underscore)\n",
    "            video_name = filename.split('_')[0]\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            img = cv2.imread(filepath)\n",
    "\n",
    "            if img is not None:\n",
    "                # Resize and preprocess the image\n",
    "                img = cv2.resize(img, IMG_SIZE)\n",
    "                img = img_to_array(img)\n",
    "                img = preprocess_input(img)  # Preprocess using InceptionV3 preprocessing\n",
    "                video_frames[video_name].append(img)\n",
    "    \n",
    "    # Process each set of images grouped by videoname\n",
    "    for frames in video_frames.values():\n",
    "        # Pad with zeros if frames are less than MAX_FRAMES\n",
    "        while len(frames) < MAX_FRAMES:\n",
    "            frames.append(np.zeros((299, 299, 3)))  # Zero-padding for missing frames\n",
    "\n",
    "        # Limit to MAX_FRAMES if more frames are present\n",
    "        frames = frames[:MAX_FRAMES]\n",
    "\n",
    "        data.append(frames)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return np.array(data), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ccc828",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_to_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m FAKE_DIR = \u001b[33m\"\u001b[39m\u001b[33mDataset/fake\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load real and fake images\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m x_real, y_real = \u001b[43mload_images_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mREAL_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Label 0 for real\u001b[39;00m\n\u001b[32m      5\u001b[39m x_fake, y_fake = load_images_from_directory(FAKE_DIR, label=\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# Label 1 for fake\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mload_images_from_directory\u001b[39m\u001b[34m(directory, label)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# Resize and preprocess the image\u001b[39;00m\n\u001b[32m     44\u001b[39m     img = cv2.resize(img, IMG_SIZE)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     img = \u001b[43mimg_to_array\u001b[49m(img)\n\u001b[32m     46\u001b[39m     img = preprocess_input(img)  \u001b[38;5;66;03m# Preprocess using InceptionV3 preprocessing\u001b[39;00m\n\u001b[32m     47\u001b[39m     video_frames[video_name].append(img)\n",
      "\u001b[31mNameError\u001b[39m: name 'img_to_array' is not defined"
     ]
    }
   ],
   "source": [
    "REAL_DIR = \"Dataset/real\"\n",
    "FAKE_DIR = \"Dataset/fake\"\n",
    "# Load real and fake images\n",
    "x_real, y_real = load_images_from_directory(REAL_DIR, label=0)  # Label 0 for real\n",
    "x_fake, y_fake = load_images_from_directory(FAKE_DIR, label=1)  # Label 1 for fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab94b4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfakevenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
